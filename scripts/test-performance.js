/**
 * ÊÄßËÉΩÊµãËØïÂ∑•ÂÖ∑
 * ÊµãËØï Gemini API ÁöÑÂÆûÈôÖÂìçÂ∫îÊó∂Èó¥
 */

const { fetch, ProxyAgent } = require('undici')
require('dotenv').config({ path: '.env.local' })

const API_KEY = process.env.GOOGLE_GEMINI_API_KEY
const MODEL = process.env.GOOGLE_GEMINI_MODEL || 'gemini-2.5-flash'
const PROXY_URL = process.env.GEMINI_PROXY_URL || process.env.HTTPS_PROXY || process.env.HTTP_PROXY

if (!API_KEY || API_KEY === 'your-gemini-api-key') {
  console.error('‚ùå GOOGLE_GEMINI_API_KEY not configured')
  process.exit(1)
}

const API_URL = `https://generativelanguage.googleapis.com/v1beta/models/${MODEL}:streamGenerateContent?key=${API_KEY}`

async function testPerformance() {
  console.log('‚ö° Performance Test - Gemini API')
  console.log('=' .repeat(60))
  console.log('Model:', MODEL)
  console.log('Proxy:', PROXY_URL || 'None (direct connection)')
  console.log('=' .repeat(60))
  console.log()

  // ÊµãËØï‰ª£ÁêÜÂª∂Ëøü
  if (PROXY_URL) {
    console.log('üì° Testing proxy latency...')
    try {
      const proxyAgent = new ProxyAgent(PROXY_URL)
      const startTime = Date.now()
      const response = await fetch('https://www.google.com', {
        dispatcher: proxyAgent,
      })
      const endTime = Date.now()
      const latency = endTime - startTime
      console.log(`   Proxy latency: ${latency}ms`)
      if (latency > 500) {
        console.log(`   ‚ö†Ô∏è  High latency! This may be the main bottleneck.`)
      }
      console.log()
    } catch (e) {
      console.log(`   ‚ùå Proxy test failed: ${e.message}`)
      console.log()
    }
  }

  // ÊµãËØï Gemini API ÂìçÂ∫îÊó∂Èó¥
  console.log('üöÄ Testing Gemini API response time...')
  console.log()

  try {
    const proxyAgent = PROXY_URL ? new ProxyAgent(PROXY_URL) : undefined
    
    const fetchOptions = {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Connection': 'keep-alive',
      },
      body: JSON.stringify({
        contents: [{
          role: 'user',
          parts: [{ text: 'Say hello in one sentence.' }]
        }],
        generationConfig: {
          temperature: 0.8,
          topK: 40,
          topP: 0.95,
          maxOutputTokens: 100,
        }
      }),
      dispatcher: proxyAgent,
    }

    const requestStart = Date.now()
    const response = await fetch(API_URL, fetchOptions)
    const requestEnd = Date.now()
    
    console.log(`üì• Request time: ${requestEnd - requestStart}ms`)
    console.log(`üì• Status: ${response.status}`)
    console.log(`üì• Content-Type: ${response.headers.get('content-type')}`)
    console.log()

    if (!response.ok) {
      const errorText = await response.text()
      console.error('‚ùå API Error:', errorText)
      return
    }

    if (!response.body) {
      console.error('‚ùå No response body')
      return
    }

    console.log('üìä Measuring stream performance...')
    console.log()

    const reader = response.body.getReader()
    const decoder = new TextDecoder()
    let buffer = ''
    let firstChunkTime = null
    let firstDataTime = null
    let totalBytes = 0
    let chunkCount = 0

    const streamStart = Date.now()

    while (true) {
      const { done, value } = await reader.read()
      
      if (done) {
        break
      }

      chunkCount++
      totalBytes += value.length
      
      if (!firstChunkTime) {
        firstChunkTime = Date.now()
        console.log(`‚úÖ First chunk received: ${firstChunkTime - streamStart}ms`)
        console.log(`   Chunk size: ${value.length} bytes`)
      }

      const chunk = decoder.decode(value, { stream: true })
      buffer += chunk

      // Â∞ùËØïËß£ÊûêÁ¨¨‰∏Ä‰∏™Êï∞ÊçÆ
      if (!firstDataTime) {
        try {
          // Êü•ÊâæÁ¨¨‰∏Ä‰∏™ÂÆåÊï¥ÁöÑJSONÂØπË±°
          const arrayEnd = buffer.indexOf(']')
          if (arrayEnd !== -1) {
            const arrayStr = buffer.substring(0, arrayEnd + 1)
            const array = JSON.parse(arrayStr)
            if (Array.isArray(array) && array.length > 0) {
              const text = array[0]?.candidates?.[0]?.content?.parts?.[0]?.text
              if (text) {
                firstDataTime = Date.now()
                console.log(`‚úÖ First data extracted: ${firstDataTime - streamStart}ms`)
                console.log(`   Text: "${text.substring(0, 50)}..."`)
              }
            }
          }
        } catch (e) {
          // ÁªßÁª≠Á≠âÂæÖ
        }
      }
    }

    const streamEnd = Date.now()
    const totalTime = streamEnd - streamStart

    console.log()
    console.log('=' .repeat(60))
    console.log('üìä Performance Summary:')
    console.log('=' .repeat(60))
    console.log(`Total time: ${totalTime}ms (${(totalTime/1000).toFixed(2)}s)`)
    console.log(`Request time: ${requestEnd - requestStart}ms`)
    if (firstChunkTime) {
      console.log(`TTFB (Time to First Byte): ${firstChunkTime - streamStart}ms`)
    }
    if (firstDataTime) {
      console.log(`Time to first data: ${firstDataTime - streamStart}ms`)
    }
    console.log(`Total chunks: ${chunkCount}`)
    console.log(`Total bytes: ${totalBytes}`)
    console.log()

    // ÊÄßËÉΩËØÑ‰º∞
    if (totalTime > 5000) {
      console.log('‚ö†Ô∏è  Performance Warning:')
      if (requestEnd - requestStart > 2000) {
        console.log('   - High request latency (network/proxy issue)')
      }
      if (firstChunkTime && firstChunkTime - streamStart > 2000) {
        console.log('   - High TTFB (network/proxy issue)')
      }
      if (PROXY_URL) {
        console.log('   - Consider testing without proxy or using a faster proxy')
      }
    } else {
      console.log('‚úÖ Performance is good!')
    }

  } catch (error) {
    console.error('‚ùå Test failed:', error)
    console.error('Stack:', error instanceof Error ? error.stack : 'No stack')
  }
}

testPerformance().catch(console.error)

